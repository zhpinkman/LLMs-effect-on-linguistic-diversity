{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from langchain_ollama import ChatOllama\n",
    "from collections import defaultdict\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(\n",
    "    model=\"llama3.1\",\n",
    "    temperature=0,\n",
    "    num_predict=5,\n",
    ")\n",
    "\n",
    "\n",
    "personality_df = pd.read_csv(\"essays/essays_anon_full.csv\")\n",
    "facebook_df = pd.read_csv(\"facebook/full_dataset_clean.csv\")\n",
    "demographic_df = pd.read_csv(\"political/clean_data.csv\")\n",
    "wassa_df = pd.read_csv(\"wassa/clean_wassa.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random baseline f1:  0.4902500486655\n"
     ]
    }
   ],
   "source": [
    "possible_values = [\"D\", \"R\"]\n",
    "random_selects = np.random.choice(possible_values, demographic_df.shape[0])\n",
    "\n",
    "print(\n",
    "    \"random baseline f1: \",\n",
    "    f1_score(demographic_df[\"party\"], random_selects, average=\"weighted\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "personality_df = personality_df.sample(n=100)\n",
    "facebook_df = facebook_df.sample(n=100)\n",
    "demographic_df = demographic_df.sample(n=100)\n",
    "wassa_df = wassa_df.sample(n=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>cEXT</th>\n",
       "      <th>cNEU</th>\n",
       "      <th>cAGR</th>\n",
       "      <th>cCON</th>\n",
       "      <th>cOPN</th>\n",
       "      <th>sEXT</th>\n",
       "      <th>sNEU</th>\n",
       "      <th>sAGR</th>\n",
       "      <th>sCON</th>\n",
       "      <th>sOPN</th>\n",
       "      <th>zEXT</th>\n",
       "      <th>zNEU</th>\n",
       "      <th>zAGR</th>\n",
       "      <th>zCON</th>\n",
       "      <th>zOPN</th>\n",
       "      <th>#AUTHID</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>Female</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>22.000</td>\n",
       "      <td>50.000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-3.043693</td>\n",
       "      <td>1.722684</td>\n",
       "      <td>-1.208785</td>\n",
       "      <td>-0.591187</td>\n",
       "      <td>1.118603</td>\n",
       "      <td>1997_714973</td>\n",
       "      <td>I will now try to track my cluttered and rando...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>Female</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "      <td>41.000</td>\n",
       "      <td>38.000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>44.0</td>\n",
       "      <td>-0.362433</td>\n",
       "      <td>0.521287</td>\n",
       "      <td>-1.655192</td>\n",
       "      <td>0.175054</td>\n",
       "      <td>0.532741</td>\n",
       "      <td>1998_163952</td>\n",
       "      <td>He will be nineteen this Saturday. I think I a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2201</th>\n",
       "      <td>Female</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "      <td>29.000</td>\n",
       "      <td>27.000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.427746</td>\n",
       "      <td>0.486658</td>\n",
       "      <td>0.126914</td>\n",
       "      <td>0.868764</td>\n",
       "      <td>1.208117</td>\n",
       "      <td>2004_298</td>\n",
       "      <td>So. I am overwhelmed. I wouldn't say that I'm ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>Female</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>3.875</td>\n",
       "      <td>4.125</td>\n",
       "      <td>3.111111</td>\n",
       "      <td>3.222222</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.623297</td>\n",
       "      <td>1.444437</td>\n",
       "      <td>-1.142632</td>\n",
       "      <td>-0.432014</td>\n",
       "      <td>-0.790909</td>\n",
       "      <td>2000_672399</td>\n",
       "      <td>I just woke up and I'm a little confused as I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>Female</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>35.000</td>\n",
       "      <td>34.000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>42.0</td>\n",
       "      <td>-1.183799</td>\n",
       "      <td>-0.087609</td>\n",
       "      <td>0.929513</td>\n",
       "      <td>-0.224488</td>\n",
       "      <td>0.174959</td>\n",
       "      <td>1999_498508</td>\n",
       "      <td>I can't wait to drive back from dallas to aust...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>Male</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>48.000</td>\n",
       "      <td>31.000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.698073</td>\n",
       "      <td>-0.319336</td>\n",
       "      <td>0.355608</td>\n",
       "      <td>1.591758</td>\n",
       "      <td>-1.237685</td>\n",
       "      <td>1998_511209</td>\n",
       "      <td>I want to get good grades in all my classes. M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1148</th>\n",
       "      <td>Male</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>3.000</td>\n",
       "      <td>2.500</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2.888889</td>\n",
       "      <td>3.4</td>\n",
       "      <td>-0.348052</td>\n",
       "      <td>-0.616330</td>\n",
       "      <td>-1.842456</td>\n",
       "      <td>-0.924518</td>\n",
       "      <td>-0.631214</td>\n",
       "      <td>2000_559995</td>\n",
       "      <td>I feel really good today because it is my birt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Female</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "      <td>48.000</td>\n",
       "      <td>36.000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.698598</td>\n",
       "      <td>0.042114</td>\n",
       "      <td>-0.067130</td>\n",
       "      <td>0.463697</td>\n",
       "      <td>0.241172</td>\n",
       "      <td>1997_071933</td>\n",
       "      <td>So far I have been at LOCNAME for I guess 0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Female</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>31.000</td>\n",
       "      <td>45.000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>33.0</td>\n",
       "      <td>-1.748285</td>\n",
       "      <td>1.122480</td>\n",
       "      <td>-0.393317</td>\n",
       "      <td>1.123000</td>\n",
       "      <td>-1.367451</td>\n",
       "      <td>1997_454257</td>\n",
       "      <td>September 0, 0000   I am not too sure what to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>Male</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>2.750</td>\n",
       "      <td>2.500</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.4</td>\n",
       "      <td>-0.625581</td>\n",
       "      <td>-0.616330</td>\n",
       "      <td>-2.367324</td>\n",
       "      <td>0.224658</td>\n",
       "      <td>-0.631214</td>\n",
       "      <td>2000_399465</td>\n",
       "      <td>Well another night of staying up late. I don't...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender cEXT cNEU cAGR cCON cOPN    sEXT    sNEU       sAGR       sCON  \\\n",
       "164   Female    n    y    n    n    y  22.000  50.000  34.000000  37.000000   \n",
       "362   Female    n    y    n    y    y  41.000  38.000  32.000000  42.000000   \n",
       "2201  Female    y    y    y    y    y  29.000  27.000  35.000000  37.000000   \n",
       "1229  Female    y    y    n    n    n   3.875   4.125   3.111111   3.222222   \n",
       "689   Female    n    n    y    n    y  35.000  34.000  49.000000  39.000000   \n",
       "...      ...  ...  ...  ...  ...  ...     ...     ...        ...        ...   \n",
       "421     Male    y    n    y    y    n  48.000  31.000  45.000000  49.000000   \n",
       "1148    Male    n    n    n    n    n   3.000   2.500   2.666667   2.888889   \n",
       "10    Female    y    y    n    y    y  48.000  36.000  41.000000  45.000000   \n",
       "59    Female    n    y    n    y    n  31.000  45.000  39.000000  50.000000   \n",
       "1097    Male    n    n    n    y    n   2.750   2.500   2.333333   3.666667   \n",
       "\n",
       "      sOPN      zEXT      zNEU      zAGR      zCON      zOPN      #AUTHID  \\\n",
       "164   50.0 -3.043693  1.722684 -1.208785 -0.591187  1.118603  1997_714973   \n",
       "362   44.0 -0.362433  0.521287 -1.655192  0.175054  0.532741  1998_163952   \n",
       "2201  45.0  0.427746  0.486658  0.126914  0.868764  1.208117     2004_298   \n",
       "1229   3.3  0.623297  1.444437 -1.142632 -0.432014 -0.790909  2000_672399   \n",
       "689   42.0 -1.183799 -0.087609  0.929513 -0.224488  0.174959  1999_498508   \n",
       "...    ...       ...       ...       ...       ...       ...          ...   \n",
       "421   32.0  0.698073 -0.319336  0.355608  1.591758 -1.237685  1998_511209   \n",
       "1148   3.4 -0.348052 -0.616330 -1.842456 -0.924518 -0.631214  2000_559995   \n",
       "10    44.0  0.698598  0.042114 -0.067130  0.463697  0.241172  1997_071933   \n",
       "59    33.0 -1.748285  1.122480 -0.393317  1.123000 -1.367451  1997_454257   \n",
       "1097   3.4 -0.625581 -0.616330 -2.367324  0.224658 -0.631214  2000_399465   \n",
       "\n",
       "                                                   text  \n",
       "164   I will now try to track my cluttered and rando...  \n",
       "362   He will be nineteen this Saturday. I think I a...  \n",
       "2201  So. I am overwhelmed. I wouldn't say that I'm ...  \n",
       "1229  I just woke up and I'm a little confused as I ...  \n",
       "689   I can't wait to drive back from dallas to aust...  \n",
       "...                                                 ...  \n",
       "421   I want to get good grades in all my classes. M...  \n",
       "1148  I feel really good today because it is my birt...  \n",
       "10      So far I have been at LOCNAME for I guess 0 ...  \n",
       "59    September 0, 0000   I am not too sure what to ...  \n",
       "1097  Well another night of staying up late. I don't...  \n",
       "\n",
       "[100 rows x 18 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "personality_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "personality_results = defaultdict(list)\n",
    "for col in [\"EXT\", \"NEU\", \"AGR\", \"CON\", \"OPN\"]:\n",
    "    for index, row in tqdm(\n",
    "        personality_df.iterrows(), total=personality_df.shape[0], leave=False\n",
    "    ):\n",
    "        text = row[\"text\"]\n",
    "        col_str = f\"c{col}\"\n",
    "        complete_col_string_dictionary = {\n",
    "            \"EXT\": \"extrovert\",\n",
    "            \"NEU\": \"neurotic\",\n",
    "            \"AGR\": \"agreeable\",\n",
    "            \"CON\": \"conscientious\",\n",
    "            \"OPN\": \"open\",\n",
    "        }\n",
    "        complete_col_string = complete_col_string_dictionary[col]\n",
    "        messages = [\n",
    "            (\n",
    "                \"system\",\n",
    "                f\"You are a helpful assistant that predict whether the text given to you is written by an {complete_col_string} or not. Can you predict the personality of the following text? ONLY return YES or NO.\",\n",
    "            ),\n",
    "            (\"human\", text),\n",
    "        ]\n",
    "        ai_msg = llm.invoke(messages)\n",
    "\n",
    "        personality_results[col].append((ai_msg.content, row[col_str]))\n",
    "import joblib\n",
    "\n",
    "joblib.dump(personality_results, \"personality_results.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wassa_results = defaultdict(list)\n",
    "for col in [\"c.iri.perspective\", \"c.iri.distress\", \"c.iri.fantasy\", \"c.iri.concern\"]:\n",
    "    for index, row in tqdm(wassa_df.iterrows(), total=wassa_df.shape[0], leave=False):\n",
    "        text = row[\"text\"]\n",
    "        col_str = col\n",
    "        complete_col_string_dictionary = {\n",
    "            \"c.iri.perspective\": \"perspective-taking\",\n",
    "            \"c.iri.distress\": \"personal distress\",\n",
    "            \"c.iri.fantasy\": \"fantasy\",\n",
    "            \"c.iri.concern\": \"empathetic concern\",\n",
    "        }\n",
    "        complete_col_string = complete_col_string_dictionary[col]\n",
    "        messages = [\n",
    "            (\n",
    "                \"system\",\n",
    "                f\"The IRI is a 28-item self-report questionnaire that measures empathy across four dimensions: perspective-taking (PT), fantasy (FS), empathetic concern (EC), and personal distress (PD). You are a helpful assistant that predict whether the text given to you is written by a person who would have high levels of {complete_col_string} or not. Can you predict that for the following text? ONLY return YES or NO.\",\n",
    "            ),\n",
    "            (\"human\", text),\n",
    "        ]\n",
    "        ai_msg = llm.invoke(messages)\n",
    "\n",
    "        wassa_results[col].append((ai_msg.content, row[col_str]))\n",
    "import joblib\n",
    "\n",
    "joblib.dump(wassa_results, \"wassa_results.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Care</th>\n",
       "      <th>Fairness</th>\n",
       "      <th>Loyalty</th>\n",
       "      <th>Authority</th>\n",
       "      <th>Purity</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>z.care</th>\n",
       "      <th>z.fairness</th>\n",
       "      <th>z.loyalty</th>\n",
       "      <th>z.authority</th>\n",
       "      <th>z.purity</th>\n",
       "      <th>c.care</th>\n",
       "      <th>c.fairness</th>\n",
       "      <th>c.loyalty</th>\n",
       "      <th>c.authority</th>\n",
       "      <th>c.purity</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1784</th>\n",
       "      <td>1.833333</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>31</td>\n",
       "      <td>Female</td>\n",
       "      <td>-1.908364</td>\n",
       "      <td>-1.069538</td>\n",
       "      <td>-1.331858</td>\n",
       "      <td>-0.644126</td>\n",
       "      <td>-1.279359</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>1431503</td>\n",
       "      <td>It is done. Now alcohol.; deep breaths.....; P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>53</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.630885</td>\n",
       "      <td>-0.408393</td>\n",
       "      <td>-0.440891</td>\n",
       "      <td>-1.466191</td>\n",
       "      <td>-0.484143</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>1418784</td>\n",
       "      <td>With Lisa Stephen to see Grisly hand and JD Mc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>26</td>\n",
       "      <td>Male</td>\n",
       "      <td>-1.713037</td>\n",
       "      <td>0.913898</td>\n",
       "      <td>-2.044632</td>\n",
       "      <td>-1.795017</td>\n",
       "      <td>-1.146823</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>1402941</td>\n",
       "      <td>I can finally drive my car, just passed my dri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Care  Fairness   Loyalty  Authority    Purity  age  gender  \\\n",
       "1784  1.833333  2.666667  1.166667   1.833333  0.333333   31  Female   \n",
       "972   4.000000  3.166667  2.000000   1.000000  1.333333   53    Male   \n",
       "505   2.000000  4.166667  0.500000   0.666667  0.500000   26    Male   \n",
       "\n",
       "        z.care  z.fairness  z.loyalty  z.authority  z.purity c.care  \\\n",
       "1784 -1.908364   -1.069538  -1.331858    -0.644126 -1.279359      n   \n",
       "972   0.630885   -0.408393  -0.440891    -1.466191 -0.484143      y   \n",
       "505  -1.713037    0.913898  -2.044632    -1.795017 -1.146823      n   \n",
       "\n",
       "     c.fairness c.loyalty c.authority c.purity  subject_id  \\\n",
       "1784          n         n           n        n     1431503   \n",
       "972           n         n           n        n     1418784   \n",
       "505           y         n           n        n     1402941   \n",
       "\n",
       "                                                   text  \n",
       "1784  It is done. Now alcohol.; deep breaths.....; P...  \n",
       "972   With Lisa Stephen to see Grisly hand and JD Mc...  \n",
       "505   I can finally drive my car, just passed my dri...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "facebook_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facebook_results = defaultdict(list)\n",
    "for col in [\"c.care\", \"c.fairness\", \"c.loyalty\", \"c.authority\", \"c.purity\"]:\n",
    "    for index, row in tqdm(\n",
    "        facebook_df.iterrows(), total=facebook_df.shape[0], leave=False\n",
    "    ):\n",
    "        text = row[\"text\"]\n",
    "        col_str = col\n",
    "        complete_col_string_dictionary = {\n",
    "            \"c.care\": \"care\",\n",
    "            \"c.fairness\": \"fairness\",\n",
    "            \"c.loyalty\": \"loyalty\",\n",
    "            \"c.authority\": \"authority\",\n",
    "            \"c.purity\": \"purity\",\n",
    "        }\n",
    "        complete_col_string = complete_col_string_dictionary[col]\n",
    "        messages = [\n",
    "            (\n",
    "                \"system\",\n",
    "                f\"The Moral Foundations Questionnaire (MFQ) is a measure of the five foundations of morality. You are a helpful assistant that predict whether the text given to you is written by a person who would have high levels of {complete_col_string} or not. Can you predict that for the following text? ONLY return YES or NO.\",\n",
    "            ),\n",
    "            (\"human\", text),\n",
    "        ]\n",
    "        ai_msg = llm.invoke(messages)\n",
    "\n",
    "        facebook_results[col].append((ai_msg.content, row[col_str]))\n",
    "\n",
    "import joblib\n",
    "\n",
    "joblib.dump(facebook_results, \"facebook_results.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aa493b0e1a84ce89cfbc98ac816a409",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['party_results.joblib']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "party_results = defaultdict(list)\n",
    "\n",
    "for index, row in tqdm(\n",
    "    demographic_df.iterrows(), total=demographic_df.shape[0], leave=False\n",
    "):\n",
    "    text = row[\"text\"]\n",
    "    messages = [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant that predict whether the text given to you is written by a person who would be a Democrat or not. Can you predict the political affiliation of the following text? ONLY return YES or NO.\",\n",
    "        ),\n",
    "        (\"human\", text),\n",
    "    ]\n",
    "    ai_msg = llm.invoke(messages)\n",
    "\n",
    "    party_results[col].append((ai_msg.content, row[\"party\"]))\n",
    "\n",
    "\n",
    "joblib.dump(party_results, \"party_results.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d504a98ed0aa464ab3d07145f4c9d866",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['gender_results.joblib']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_results = defaultdict(list)\n",
    "\n",
    "for index, row in tqdm(\n",
    "    demographic_df.iterrows(), total=demographic_df.shape[0], leave=False\n",
    "):\n",
    "    text = row[\"text\"]\n",
    "    messages = [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant that predict whether the text given to you is written by a person who would be male or not. Can you predict the the gender of the following text? ONLY return YES or NO.\",\n",
    "        ),\n",
    "        (\"human\", text),\n",
    "    ]\n",
    "    ai_msg = llm.invoke(messages)\n",
    "\n",
    "    gender_results[col].append((ai_msg.content, row[\"gender\"]))\n",
    "\n",
    "\n",
    "joblib.dump(gender_results, \"gender_results.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c64bc2a554ec4e98a1657d43a7b99b66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['cohort_resutls.joblib']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohort_resutls = defaultdict(list)\n",
    "\n",
    "for index, row in tqdm(\n",
    "    demographic_df.iterrows(), total=demographic_df.shape[0], leave=False\n",
    "):\n",
    "    text = row[\"text\"]\n",
    "    messages = [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant that predict whether the text given to you is written by (a) a person between 27-40 years old, (b) a person between 41-55 years also, (c) a person between 56-70 years old, or (d) a person more than 70 years old. Can you predict the age cohort of the following text? ONLY return the letter (a, b, c, or d).\",\n",
    "        ),\n",
    "        (\"human\", text),\n",
    "    ]\n",
    "    ai_msg = llm.invoke(messages)\n",
    "\n",
    "    cohort_resutls[col].append((ai_msg.content, row[\"cohort\"]))\n",
    "\n",
    "\n",
    "joblib.dump(cohort_resutls, \"cohort_resutls.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 4, 5, 1, 1, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(personality_results), len(wassa_results), len(facebook_results), len(\n",
    "    party_results\n",
    "), len(cohort_resutls), len(gender_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXT\n",
      "0.3661971830985915\n",
      "-----------------\n",
      "NEU\n",
      "0.6950354609929078\n",
      "-----------------\n",
      "AGR\n",
      "0.6153846153846153\n",
      "-----------------\n",
      "CON\n",
      "0.5688073394495413\n",
      "-----------------\n",
      "OPN\n",
      "0.6\n",
      "-----------------\n",
      "Average F1 Score: 0.5690849197851312\n"
     ]
    }
   ],
   "source": [
    "all_values = []\n",
    "for key in personality_results.keys():\n",
    "    print(key)\n",
    "    actual_values = [x[0] for x in personality_results[key]]\n",
    "    actual_values = [0 if \"NO\" in x else 1 for x in actual_values]\n",
    "    ground_truth = [x[1] for x in personality_results[key]]\n",
    "    ground_truth = [0 if x == \"n\" else 1 for x in ground_truth]\n",
    "    print(f1_score(ground_truth, actual_values))\n",
    "    all_values.append(f1_score(ground_truth, actual_values))\n",
    "    print(\"-----------------\")\n",
    "print(\"Average F1 Score:\", np.mean(all_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c.iri.perspective\n",
      "0.5384615384615384\n",
      "-----------------\n",
      "c.iri.distress\n",
      "0.5818181818181819\n",
      "-----------------\n",
      "c.iri.fantasy\n",
      "0.0625\n",
      "-----------------\n",
      "c.iri.concern\n",
      "0.5625\n",
      "-----------------\n",
      "Average F1 Score: 0.4363199300699301\n"
     ]
    }
   ],
   "source": [
    "all_values = []\n",
    "for key in wassa_results.keys():\n",
    "    print(key)\n",
    "    actual_values = [x[0] for x in wassa_results[key]]\n",
    "    actual_values = [0 if \"NO\" in x else 1 for x in actual_values]\n",
    "    ground_truth = [x[1] for x in wassa_results[key]]\n",
    "    ground_truth = [0 if x == \"n\" else 1 for x in ground_truth]\n",
    "    print(f1_score(ground_truth, actual_values))\n",
    "    all_values.append(f1_score(ground_truth, actual_values))\n",
    "    print(\"-----------------\")\n",
    "print(\"Average F1 Score:\", np.mean(all_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c.care\n",
      "0.5567010309278351\n",
      "-----------------\n",
      "c.fairness\n",
      "0.3888888888888889\n",
      "-----------------\n",
      "c.loyalty\n",
      "0.47191011235955055\n",
      "-----------------\n",
      "c.authority\n",
      "0.2857142857142857\n",
      "-----------------\n",
      "c.purity\n",
      "0.32352941176470584\n",
      "-----------------\n",
      "Average F1 Score: 0.40534874593105313\n"
     ]
    }
   ],
   "source": [
    "all_values = []\n",
    "for key in facebook_results.keys():\n",
    "    print(key)\n",
    "    actual_values = [x[0] for x in facebook_results[key]]\n",
    "    actual_values = [0 if \"NO\" in x else 1 for x in actual_values]\n",
    "    ground_truth = [x[1] for x in facebook_results[key]]\n",
    "    ground_truth = [0 if x == \"n\" else 1 for x in ground_truth]\n",
    "    print(f1_score(ground_truth, actual_values))\n",
    "    all_values.append(f1_score(ground_truth, actual_values))\n",
    "    print(\"-----------------\")\n",
    "print(\"Average F1 Score:\", np.mean(all_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6021505376344085\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "for key in party_results.keys():\n",
    "    actual_values = [x[0] for x in party_results[key]]\n",
    "    actual_values = [0 if \"NO\" in x else 1 for x in actual_values]\n",
    "    ground_truth = [x[1] for x in party_results[key]]\n",
    "    ground_truth = [0 if x == \"R\" else 1 for x in ground_truth]\n",
    "    print(f1_score(ground_truth, actual_values))\n",
    "    print(\"-----------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49484536082474234\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "for key in gender_results.keys():\n",
    "    actual_values = [x[0] for x in gender_results[key]]\n",
    "    actual_values = [0 if \"NO\" in x else 1 for x in actual_values]\n",
    "    ground_truth = [x[1] for x in gender_results[key]]\n",
    "    ground_truth = [0 if x == \"F\" else 1 for x in ground_truth]\n",
    "    print(f1_score(ground_truth, actual_values))\n",
    "    print(\"-----------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12110783349721403\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "for key in cohort_resutls.keys():\n",
    "    actual_values = [x[0] for x in cohort_resutls[key]]\n",
    "    actual_values = [\n",
    "        0 if \"a\" in x else 1 if \"b\" in x else 2 if \"c\" in x else 3\n",
    "        for x in actual_values\n",
    "    ]\n",
    "    ground_truth = [x[1] for x in cohort_resutls[key]]\n",
    "    ground_truth = [\n",
    "        0 if x == \"27-40\" else 1 if x == \"41-55\" else 2 if x == \"56-70\" else 3\n",
    "        for x in ground_truth\n",
    "    ]\n",
    "    print(f1_score(ground_truth, actual_values, average=\"macro\"))\n",
    "    print(\"-----------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
