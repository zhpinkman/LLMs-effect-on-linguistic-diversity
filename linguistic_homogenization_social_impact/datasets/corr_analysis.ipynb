{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhivar/anaconda3/envs/py310/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ttest_ind, ttest_rel\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "personality_columns = [\n",
    "    \"nrc.negative\",\n",
    "    \"emo_pos\",\n",
    "    \"Affect\",\n",
    "    \"nrc.positive\",\n",
    "    \"affiliation\",\n",
    "    \"emotion\",\n",
    "    \"nrc.joy\",\n",
    "    \"Social\",\n",
    "    \"emo_sad\",\n",
    "    \"nrc.anticipation\",\n",
    "    \"nrc.anger\",\n",
    "    \"pronoun\",\n",
    "    \"i\",\n",
    "    \"emo_anger\",\n",
    "    \"swear\",\n",
    "    \"BigWords\",\n",
    "    \"emo_neg\",\n",
    "    \"nrc.disgust\",\n",
    "    \"nrc.sadness\",\n",
    "    \"nrc.trust\",\n",
    "]\n",
    "\n",
    "facebook_columns = [\n",
    "    \"we\",\n",
    "    \"socrefs\",\n",
    "    \"pronoun\",\n",
    "    \"friend\",\n",
    "    \"mfd.authority.virtue\",\n",
    "    \"mfd.care.virtue\",\n",
    "    \"Affect\",\n",
    "    \"i\",\n",
    "    \"mfd.authority.vice\",\n",
    "    \"affiliation\",\n",
    "    \"prosocial\",\n",
    "    \"family\",\n",
    "    \"relig\",\n",
    "    # \"mfd.purity.vice\",\n",
    "    # \"mfd.purity.virtue\",\n",
    "    \"mfd.sanctity.virtue\",\n",
    "    \"mfd.sanctity.vice\",\n",
    "    \"you\",\n",
    "    \"Social\",\n",
    "]\n",
    "\n",
    "wassa_columns = [\n",
    "    \"Affect\",\n",
    "    \"differ\",\n",
    "    \"we\",\n",
    "    \"shehe\",\n",
    "    \"pronoun\",\n",
    "    \"emo_neg\",\n",
    "    \"tentat\",\n",
    "    \"empathy.low_empathy\",\n",
    "    \"pronoun\",\n",
    "    \"cogproc\",\n",
    "    \"empathy.low_distress\",\n",
    "]\n",
    "\n",
    "political_columns = [\n",
    "    \"mfd.authority.virtue\",\n",
    "    \"mfd.authority.vice\",\n",
    "    \"mfd.loyalty.virtue\",\n",
    "    \"mfd.loyalty.vice\",\n",
    "    \"mfd.fairness.virtue\",\n",
    "    \"mfd.fairness.vice\",\n",
    "    \"emo_anx\",\n",
    "    \"adverb\",\n",
    "    \"conj\",\n",
    "    \"emo_neg\",\n",
    "    \"emo_anger\",\n",
    "    \"we\",\n",
    "    \"relig\",\n",
    "    \"swear\",\n",
    "    \"i\",\n",
    "    \"cogproc\",\n",
    "    \"emo_pos\",\n",
    "    \"certitude\",\n",
    "]\n",
    "\n",
    "gender_columns = [\n",
    "    \"article\",\n",
    "    \"social\",\n",
    "    \"emo_anx\",\n",
    "    \"pronoun\",\n",
    "    \"i\",\n",
    "    \"emo_pos\",\n",
    "    \"emo_neg\",\n",
    "    \"affect\",\n",
    "    \"tentat\",\n",
    "    \"motion\",\n",
    "    \"swear\",\n",
    "    \"quant\",\n",
    "    \"number\",\n",
    "    \"space\",\n",
    "    \"cogproc\",\n",
    "]\n",
    "\n",
    "age_columns = [\n",
    "    \"we\",\n",
    "    \"cogproc\",\n",
    "    \"prep\",\n",
    "    \"article\",\n",
    "    \"social\",\n",
    "    \"focusfuture\",\n",
    "    \"focuspast\",\n",
    "    \"emo_neg\",\n",
    "    \"emo_pos\",\n",
    "    \"i\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Essays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_path = \"essays/with_dictionaries/\"\n",
    "all_files = os.listdir(parent_path)\n",
    "original_df = pd.read_csv(\n",
    "    os.path.join(parent_path, [file for file in all_files if \"anon_full\" in file][0])\n",
    ")\n",
    "syntax_grammar_llama = pd.read_csv(\n",
    "    os.path.join(\n",
    "        parent_path, [file for file in all_files if \"syntax_grammar_llama\" in file][0]\n",
    "    )\n",
    ")\n",
    "rephrase_llama = pd.read_csv(\n",
    "    os.path.join(\n",
    "        parent_path, [file for file in all_files if \"rephrase_llama\" in file][0]\n",
    "    )\n",
    ")\n",
    "syntax_grammar_gpt = pd.read_csv(\n",
    "    os.path.join(\n",
    "        parent_path, [file for file in all_files if \"syntax_grammar_gpt\" in file][0]\n",
    "    )\n",
    ")\n",
    "rephrase_gpt = pd.read_csv(\n",
    "    os.path.join(parent_path, [file for file in all_files if \"rephrase_gpt\" in file][0])\n",
    ")\n",
    "syntax_grammar_gemini = pd.read_csv(\n",
    "    os.path.join(\n",
    "        parent_path, [file for file in all_files if \"syntax_grammar_gemini\" in file][0]\n",
    "    )\n",
    ")\n",
    "rephrase_gemini = pd.read_csv(\n",
    "    os.path.join(\n",
    "        parent_path, [file for file in all_files if \"rephrase_gemini\" in file][0]\n",
    "    )\n",
    ")\n",
    "\n",
    "all_data_dictionaries = {\n",
    "    (\"original\", \"-\"): original_df,\n",
    "    (\"syntax_grammar\", \"llama\"): syntax_grammar_llama,\n",
    "    (\"rephrase\", \"llama\"): rephrase_llama,\n",
    "    (\"syntax_grammar\", \"gpt\"): syntax_grammar_gpt,\n",
    "    (\"rephrase\", \"gpt\"): rephrase_gpt,\n",
    "    (\"syntax_grammar\", \"gemini\"): syntax_grammar_gemini,\n",
    "    (\"rephrase\", \"gemini\"): rephrase_gemini,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in personality_columns:\n",
    "    if col not in original_df.columns:\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# column of interest: AGR\n",
      " & nrc.negative & \\textbf{-0.10} & -0.04 & -0.05 & -0.06 & \\textbf{-0.08} & \\textbf{-0.07} & \\textbf{-0.07}\\\\\n",
      " & emo_pos & \\textbf{0.06} & 0.04 & \\textbf{0.06} & 0.05 & \\textbf{0.07} & 0.05 & \\textbf{0.07}\\\\\n",
      " & affiliation & \\textbf{0.08} & \\textbf{0.08} & \\textbf{0.09} & \\textbf{0.07} & \\textbf{0.08} & \\textbf{0.08} & \\textbf{0.07}\\\\\n",
      " & nrc.anticipation & \\textbf{0.07} & 0.04 & \\textbf{0.08} & 0.03 & 0.04 & \\textbf{0.06} & \\textbf{0.07}\\\\\n",
      " & emo_anger & \\textbf{-0.09} & \\textbf{-0.08} & \\textbf{-0.11} & \\textbf{-0.08} & \\textbf{-0.10} & \\textbf{-0.08} & \\textbf{-0.10}\\\\\n",
      " & swear & \\textbf{-0.12} & -0.02 & \\textbf{-0.06} & -0.03 & \\textbf{-0.08} & \\textbf{-0.08} & \\textbf{-0.08}\\\\\n",
      " & nrc.disgust & \\textbf{-0.08} & -0.06 & -0.05 & -0.05 & -0.05 & \\textbf{-0.06} & -0.05\\\\\n",
      "# column of interest: OPN\n",
      " & nrc.negative & \\textbf{0.06} & 0.02 & -0.01 & -0.02 & 0.04 & 0.01 & 0.01\\\\\n",
      " & i & \\textbf{-0.13} & \\textbf{-0.07} & \\textbf{-0.11} & \\textbf{-0.07} & \\textbf{-0.14} & \\textbf{-0.12} & \\textbf{-0.09}\\\\\n",
      " & swear & \\textbf{0.09} & 0.04 & \\textbf{0.09} & \\textbf{0.06} & \\textbf{0.08} & \\textbf{0.07} & \\textbf{0.09}\\\\\n",
      " & BigWords & \\textbf{0.09} & 0.04 & 0.00 & 0.04 & \\textbf{0.07} & -0.01 & 0.03\\\\\n",
      " & nrc.disgust & \\textbf{0.09} & 0.05 & 0.03 & 0.03 & 0.06 & 0.03 & \\textbf{0.07}\\\\\n",
      "# column of interest: CON\n",
      " & nrc.negative & \\textbf{-0.06} & -0.03 & \\textbf{-0.06} & -0.04 & -0.02 & -0.06 & -0.02\\\\\n",
      " & Affect & \\textbf{-0.06} & -0.01 & -0.02 & 0.01 & -0.01 & -0.04 & -0.01\\\\\n",
      " & emo_anger & \\textbf{-0.12} & \\textbf{-0.12} & \\textbf{-0.11} & -0.04 & -0.06 & \\textbf{-0.12} & \\textbf{-0.08}\\\\\n",
      " & swear & \\textbf{-0.11} & -0.01 & \\textbf{-0.07} & -0.03 & -0.05 & \\textbf{-0.09} & \\textbf{-0.08}\\\\\n",
      " & nrc.disgust & \\textbf{-0.08} & \\textbf{-0.07} & \\textbf{-0.08} & -0.03 & -0.00 & \\textbf{-0.07} & -0.04\\\\\n",
      " & nrc.sadness & \\textbf{-0.07} & -0.03 & \\textbf{-0.07} & -0.04 & -0.02 & -0.05 & -0.03\\\\\n",
      "# column of interest: NEU\n",
      " & nrc.positive & \\textbf{-0.07} & -0.02 & \\textbf{-0.06} & \\textbf{-0.08} & -0.04 & -0.04 & \\textbf{-0.09}\\\\\n",
      " & emotion & \\textbf{0.10} & \\textbf{0.14} & \\textbf{0.12} & \\textbf{0.11} & \\textbf{0.10} & \\textbf{0.12} & \\textbf{0.06}\\\\\n",
      " & emo_sad & \\textbf{0.10} & \\textbf{0.10} & \\textbf{0.10} & \\textbf{0.10} & \\textbf{0.08} & \\textbf{0.10} & 0.05\\\\\n",
      " & nrc.anger & \\textbf{0.08} & \\textbf{0.14} & \\textbf{0.12} & \\textbf{0.15} & \\textbf{0.07} & \\textbf{0.10} & \\textbf{0.08}\\\\\n",
      " & pronoun & \\textbf{0.12} & 0.01 & \\textbf{0.11} & \\textbf{0.09} & \\textbf{0.10} & \\textbf{0.09} & \\textbf{0.10}\\\\\n",
      " & i & \\textbf{0.15} & -0.02 & \\textbf{0.16} & \\textbf{0.15} & \\textbf{0.15} & \\textbf{0.14} & \\textbf{0.12}\\\\\n",
      " & emo_anger & \\textbf{0.08} & 0.06 & \\textbf{0.07} & 0.05 & 0.06 & \\textbf{0.06} & \\textbf{0.06}\\\\\n",
      " & BigWords & \\textbf{-0.06} & 0.02 & -0.04 & -0.06 & -0.02 & -0.02 & \\textbf{-0.07}\\\\\n",
      " & emo_neg & \\textbf{0.19} & \\textbf{0.18} & \\textbf{0.20} & \\textbf{0.21} & \\textbf{0.15} & \\textbf{0.21} & \\textbf{0.18}\\\\\n",
      " & nrc.disgust & \\textbf{0.07} & \\textbf{0.08} & \\textbf{0.07} & \\textbf{0.07} & 0.02 & \\textbf{0.08} & 0.05\\\\\n",
      " & nrc.sadness & \\textbf{0.13} & \\textbf{0.12} & \\textbf{0.11} & \\textbf{0.16} & 0.06 & \\textbf{0.10} & \\textbf{0.10}\\\\\n",
      "# column of interest: EXT\n",
      " & nrc.negative & \\textbf{-0.06} & 0.00 & -0.06 & -0.04 & -0.02 & -0.04 & -0.01\\\\\n",
      " & emo_pos & \\textbf{0.10} & \\textbf{0.09} & \\textbf{0.12} & \\textbf{0.10} & 0.05 & \\textbf{0.11} & \\textbf{0.09}\\\\\n",
      " & affiliation & \\textbf{0.11} & \\textbf{0.09} & \\textbf{0.11} & \\textbf{0.09} & \\textbf{0.10} & \\textbf{0.11} & \\textbf{0.13}\\\\\n",
      " & nrc.joy & \\textbf{0.08} & \\textbf{0.07} & \\textbf{0.09} & \\textbf{0.11} & \\textbf{0.07} & \\textbf{0.09} & \\textbf{0.08}\\\\\n",
      " & Social & \\textbf{0.07} & 0.01 & \\textbf{0.08} & 0.06 & 0.04 & \\textbf{0.06} & \\textbf{0.07}\\\\\n",
      " & pronoun & \\textbf{0.06} & 0.04 & 0.05 & -0.02 & 0.04 & \\textbf{0.06} & 0.04\\\\\n",
      " & i & \\textbf{0.06} & 0.05 & 0.05 & 0.03 & \\textbf{0.06} & \\textbf{0.07} & \\textbf{0.06}\\\\\n",
      " & nrc.sadness & \\textbf{-0.06} & -0.01 & -0.04 & \\textbf{-0.06} & -0.02 & -0.02 & -0.02\\\\\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "for col_of_interest in [\"AGR\", \"OPN\", \"CON\", \"NEU\", \"EXT\"]:\n",
    "\n",
    "    categories = []\n",
    "    llms = []\n",
    "    prompts = []\n",
    "    pearson_rs = []\n",
    "    p_values = []\n",
    "\n",
    "    threshold_based_on_bonferroni = 0.05 / 10\n",
    "\n",
    "    for key, value in all_data_dictionaries.items():\n",
    "        for column in personality_columns:\n",
    "            categories.append(column)\n",
    "            llms.append(key[0])\n",
    "            prompts.append(key[1])\n",
    "\n",
    "            pearson_r, p_value = pearsonr(\n",
    "                value.dropna(subset=[f\"z{col_of_interest}\", column])[\n",
    "                    f\"z{col_of_interest}\"\n",
    "                ],\n",
    "                value.dropna(subset=[f\"z{col_of_interest}\", column])[column],\n",
    "            )\n",
    "            pearson_rs.append(pearson_r)\n",
    "            p_values.append(p_value)\n",
    "\n",
    "    summary_df = pd.DataFrame(\n",
    "        {\n",
    "            \"category\": categories,\n",
    "            \"llm\": llms,\n",
    "            \"prompt\": prompts,\n",
    "            \"pearson_r\": pearson_rs,\n",
    "            \"p_value\": p_values,\n",
    "        }\n",
    "    )\n",
    "    summary_df[\"significant\"] = summary_df[\"p_value\"] < threshold_based_on_bonferroni\n",
    "\n",
    "    print(\"# column of interest:\", col_of_interest)\n",
    "\n",
    "    for category in summary_df[\n",
    "        (summary_df[\"significant\"]) & (summary_df[\"llm\"] == \"original\")\n",
    "    ][\"category\"].unique():\n",
    "        print(f\" & {category} & \", end=\"\")\n",
    "        original_values = summary_df[\n",
    "            (summary_df[\"category\"] == category) & (summary_df[\"llm\"] == \"original\")\n",
    "        ]\n",
    "        is_significant = original_values[\"significant\"].values[0]\n",
    "        if is_significant:\n",
    "            print(\n",
    "                f\"\\\\textbf{{{original_values['pearson_r'].values[0]:.2f}}}\",\n",
    "                end=\"\",\n",
    "            )\n",
    "        else:\n",
    "            print(\n",
    "                f\"{original_values['pearson_r'].values[0]:.2f}\",\n",
    "                end=\"\",\n",
    "            )\n",
    "        for prompt in [\"rephrase\", \"syntax_grammar\"]:\n",
    "            for llm in [\"gemini\", \"gpt\", \"llama\"]:\n",
    "                values = summary_df[\n",
    "                    (summary_df[\"category\"] == category)\n",
    "                    & (summary_df[\"llm\"] == prompt)\n",
    "                    & (summary_df[\"prompt\"] == llm)\n",
    "                ]\n",
    "                is_significant = values[\"significant\"].values[0]\n",
    "                if is_significant:\n",
    "                    print(\n",
    "                        f\" & \\\\textbf{{{values['pearson_r'].values[0]:.2f}}}\",\n",
    "                        end=\"\",\n",
    "                    )\n",
    "                else:\n",
    "                    print(\n",
    "                        f\" & {values['pearson_r'].values[0]:.2f}\",\n",
    "                        end=\"\",\n",
    "                    )\n",
    "        print(\"\\\\\\\\\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WASSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_path = \"wassa_individual/with_dictionaries/\"\n",
    "all_files = os.listdir(parent_path)\n",
    "original_df = pd.read_csv(\n",
    "    os.path.join(parent_path, [file for file in all_files if \"clean_wassa\" in file][0])\n",
    ")\n",
    "syntax_grammar_llama = pd.read_csv(\n",
    "    os.path.join(\n",
    "        parent_path, [file for file in all_files if \"syntax_grammar_llama\" in file][0]\n",
    "    )\n",
    ")\n",
    "rephrase_llama = pd.read_csv(\n",
    "    os.path.join(\n",
    "        parent_path, [file for file in all_files if \"rephrase_llama\" in file][0]\n",
    "    )\n",
    ")\n",
    "syntax_grammar_gpt = pd.read_csv(\n",
    "    os.path.join(\n",
    "        parent_path, [file for file in all_files if \"syntax_grammar_gpt\" in file][0]\n",
    "    )\n",
    ")\n",
    "rephrase_gpt = pd.read_csv(\n",
    "    os.path.join(parent_path, [file for file in all_files if \"rephrase_gpt\" in file][0])\n",
    ")\n",
    "syntax_grammar_gemini = pd.read_csv(\n",
    "    os.path.join(\n",
    "        parent_path, [file for file in all_files if \"syntax_grammar_gemini\" in file][0]\n",
    "    )\n",
    ")\n",
    "rephrase_gemini = pd.read_csv(\n",
    "    os.path.join(\n",
    "        parent_path, [file for file in all_files if \"rephrase_gemini\" in file][0]\n",
    "    )\n",
    ")\n",
    "\n",
    "all_data_dictionaries = {\n",
    "    (\"original\", \"-\"): original_df,\n",
    "    (\"syntax_grammar\", \"llama\"): syntax_grammar_llama,\n",
    "    (\"rephrase\", \"llama\"): rephrase_llama,\n",
    "    (\"syntax_grammar\", \"gpt\"): syntax_grammar_gpt,\n",
    "    (\"rephrase\", \"gpt\"): rephrase_gpt,\n",
    "    (\"syntax_grammar\", \"gemini\"): syntax_grammar_gemini,\n",
    "    (\"rephrase\", \"gemini\"): rephrase_gemini,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in wassa_columns:\n",
    "    if col not in original_df.columns:\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# column of interest: iri.perspective\n",
      " & we & \\textbf{-0.22} & \\textbf{-0.17} & \\textbf{-0.17} & \\textbf{-0.13} & \\textbf{-0.19} & \\textbf{-0.22} & \\textbf{-0.18}\\\\\n",
      " & shehe & \\textbf{0.09} & 0.03 & \\textbf{0.10} & \\textbf{0.08} & 0.04 & \\textbf{0.09} & \\textbf{0.09}\\\\\n",
      " & pronoun & \\textbf{-0.22} & -0.06 & \\textbf{-0.20} & -0.03 & \\textbf{-0.14} & \\textbf{-0.17} & \\textbf{-0.07}\\\\\n",
      " & tentat & \\textbf{-0.09} & -0.05 & \\textbf{-0.11} & 0.00 & \\textbf{-0.12} & \\textbf{-0.12} & -0.05\\\\\n",
      " & cogproc & \\textbf{-0.12} & \\textbf{-0.14} & \\textbf{-0.18} & \\textbf{-0.10} & \\textbf{-0.13} & \\textbf{-0.14} & \\textbf{-0.08}\\\\\n",
      "# column of interest: iri.distress\n",
      " & Affect & \\textbf{0.13} & 0.06 & 0.07 & \\textbf{0.09} & 0.08 & 0.06 & \\textbf{0.12}\\\\\n",
      " & differ & \\textbf{0.09} & \\textbf{0.11} & \\textbf{0.16} & \\textbf{0.09} & \\textbf{0.12} & \\textbf{0.10} & \\textbf{0.08}\\\\\n",
      " & we & \\textbf{0.08} & 0.02 & 0.07 & 0.05 & \\textbf{0.11} & 0.07 & \\textbf{0.08}\\\\\n",
      " & tentat & \\textbf{0.11} & 0.06 & \\textbf{0.07} & 0.06 & 0.05 & 0.07 & \\textbf{0.10}\\\\\n",
      " & empathy.low_distress & \\textbf{0.10} & 0.04 & -0.02 & 0.03 & -0.00 & 0.02 & \\textbf{0.10}\\\\\n",
      "# column of interest: iri.fantasy\n",
      " & Affect & \\textbf{0.08} & 0.07 & \\textbf{0.09} & 0.02 & 0.05 & \\textbf{0.12} & 0.01\\\\\n",
      " & emo_neg & \\textbf{0.11} & 0.07 & \\textbf{0.09} & 0.05 & \\textbf{0.08} & \\textbf{0.11} & \\textbf{0.07}\\\\\n",
      " & empathy.low_empathy & \\textbf{-0.08} & -0.05 & -0.03 & \\textbf{-0.08} & -0.02 & -0.04 & -0.06\\\\\n",
      " & empathy.low_distress & \\textbf{-0.10} & -0.03 & -0.01 & -0.06 & -0.02 & -0.04 & -0.07\\\\\n",
      "# column of interest: iri.concern\n",
      " & differ & \\textbf{-0.10} & -0.07 & \\textbf{-0.14} & \\textbf{-0.09} & -0.08 & \\textbf{-0.13} & \\textbf{-0.11}\\\\\n",
      " & we & \\textbf{-0.22} & \\textbf{-0.13} & \\textbf{-0.17} & \\textbf{-0.11} & \\textbf{-0.20} & \\textbf{-0.21} & \\textbf{-0.15}\\\\\n",
      " & shehe & \\textbf{0.14} & \\textbf{0.08} & \\textbf{0.14} & 0.07 & \\textbf{0.11} & \\textbf{0.13} & \\textbf{0.13}\\\\\n",
      " & pronoun & \\textbf{-0.15} & 0.00 & \\textbf{-0.13} & 0.00 & -0.07 & \\textbf{-0.11} & -0.05\\\\\n",
      " & emo_neg & \\textbf{0.13} & 0.07 & \\textbf{0.14} & \\textbf{0.11} & \\textbf{0.13} & \\textbf{0.12} & \\textbf{0.11}\\\\\n",
      " & tentat & \\textbf{-0.13} & \\textbf{-0.12} & \\textbf{-0.16} & -0.02 & \\textbf{-0.13} & \\textbf{-0.17} & \\textbf{-0.09}\\\\\n",
      " & cogproc & \\textbf{-0.13} & \\textbf{-0.12} & \\textbf{-0.14} & \\textbf{-0.12} & \\textbf{-0.13} & \\textbf{-0.13} & -0.07\\\\\n",
      " & empathy.low_distress & \\textbf{-0.09} & \\textbf{-0.09} & -0.04 & \\textbf{-0.11} & -0.05 & -0.03 & \\textbf{-0.16}\\\\\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "for col_of_interest in [\n",
    "    \"iri.perspective\",\n",
    "    \"iri.distress\",\n",
    "    \"iri.fantasy\",\n",
    "    \"iri.concern\",\n",
    "]:\n",
    "\n",
    "    categories = []\n",
    "    llms = []\n",
    "    prompts = []\n",
    "    pearson_rs = []\n",
    "    p_values = []\n",
    "\n",
    "    threshold_based_on_bonferroni = 0.05 / len(wassa_columns)\n",
    "\n",
    "    for key, value in all_data_dictionaries.items():\n",
    "        for column in wassa_columns:\n",
    "            categories.append(column)\n",
    "            llms.append(key[0])\n",
    "            prompts.append(key[1])\n",
    "\n",
    "            pearson_r, p_value = pearsonr(\n",
    "                value.dropna(subset=[f\"z.{col_of_interest}\", column])[\n",
    "                    f\"z.{col_of_interest}\"\n",
    "                ],\n",
    "                value.dropna(subset=[f\"z.{col_of_interest}\", column])[column],\n",
    "            )\n",
    "            pearson_rs.append(pearson_r)\n",
    "            p_values.append(p_value)\n",
    "\n",
    "    summary_df = pd.DataFrame(\n",
    "        {\n",
    "            \"category\": categories,\n",
    "            \"llm\": llms,\n",
    "            \"prompt\": prompts,\n",
    "            \"pearson_r\": pearson_rs,\n",
    "            \"p_value\": p_values,\n",
    "        }\n",
    "    )\n",
    "    summary_df[\"significant\"] = summary_df[\"p_value\"] < threshold_based_on_bonferroni\n",
    "\n",
    "    print(\"# column of interest:\", col_of_interest)\n",
    "\n",
    "    for category in summary_df[\n",
    "        (summary_df[\"significant\"]) & (summary_df[\"llm\"] == \"original\")\n",
    "    ][\"category\"].unique():\n",
    "        print(f\" & {category} & \", end=\"\")\n",
    "        original_values = summary_df[\n",
    "            (summary_df[\"category\"] == category) & (summary_df[\"llm\"] == \"original\")\n",
    "        ]\n",
    "        is_significant = original_values[\"significant\"].values[0]\n",
    "        if is_significant:\n",
    "            print(\n",
    "                f\"\\\\textbf{{{original_values['pearson_r'].values[0]:.2f}}}\",\n",
    "                end=\"\",\n",
    "            )\n",
    "        else:\n",
    "            print(\n",
    "                f\"{original_values['pearson_r'].values[0]:.2f}\",\n",
    "                end=\"\",\n",
    "            )\n",
    "        for prompt in [\"rephrase\", \"syntax_grammar\"]:\n",
    "            for llm in [\"gemini\", \"gpt\", \"llama\"]:\n",
    "                values = summary_df[\n",
    "                    (summary_df[\"category\"] == category)\n",
    "                    & (summary_df[\"llm\"] == prompt)\n",
    "                    & (summary_df[\"prompt\"] == llm)\n",
    "                ]\n",
    "                is_significant = values[\"significant\"].values[0]\n",
    "                if is_significant:\n",
    "                    print(\n",
    "                        f\" & \\\\textbf{{{values['pearson_r'].values[0]:.2f}}}\",\n",
    "                        end=\"\",\n",
    "                    )\n",
    "                else:\n",
    "                    print(\n",
    "                        f\" & {values['pearson_r'].values[0]:.2f}\",\n",
    "                        end=\"\",\n",
    "                    )\n",
    "        print(\"\\\\\\\\\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Facebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_path = \"facebook/with_dictionaries/\"\n",
    "all_files = os.listdir(parent_path)\n",
    "original_df = pd.read_csv(\n",
    "    os.path.join(\n",
    "        parent_path, [file for file in all_files if \"dataset_clean\" in file][0]\n",
    "    )\n",
    ")\n",
    "syntax_grammar_llama = pd.read_csv(\n",
    "    os.path.join(\n",
    "        parent_path, [file for file in all_files if \"syntax_grammar_llama\" in file][0]\n",
    "    )\n",
    ")\n",
    "rephrase_llama = pd.read_csv(\n",
    "    os.path.join(\n",
    "        parent_path, [file for file in all_files if \"rephrase_llama\" in file][0]\n",
    "    )\n",
    ")\n",
    "syntax_grammar_gpt = pd.read_csv(\n",
    "    os.path.join(\n",
    "        parent_path, [file for file in all_files if \"syntax_grammar_gpt\" in file][0]\n",
    "    )\n",
    ")\n",
    "rephrase_gpt = pd.read_csv(\n",
    "    os.path.join(parent_path, [file for file in all_files if \"rephrase_gpt\" in file][0])\n",
    ")\n",
    "syntax_grammar_gemini = pd.read_csv(\n",
    "    os.path.join(\n",
    "        parent_path, [file for file in all_files if \"syntax_grammar_gemini\" in file][0]\n",
    "    )\n",
    ")\n",
    "rephrase_gemini = pd.read_csv(\n",
    "    os.path.join(\n",
    "        parent_path, [file for file in all_files if \"rephrase_gemini\" in file][0]\n",
    "    )\n",
    ")\n",
    "\n",
    "all_data_dictionaries = {\n",
    "    (\"original\", \"-\"): original_df,\n",
    "    (\"syntax_grammar\", \"llama\"): syntax_grammar_llama,\n",
    "    (\"rephrase\", \"llama\"): rephrase_llama,\n",
    "    (\"syntax_grammar\", \"gpt\"): syntax_grammar_gpt,\n",
    "    (\"rephrase\", \"gpt\"): rephrase_gpt,\n",
    "    (\"syntax_grammar\", \"gemini\"): syntax_grammar_gemini,\n",
    "    (\"rephrase\", \"gemini\"): rephrase_gemini,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in facebook_columns:\n",
    "    if col not in original_df.columns:\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# column of interest: care\n",
      " & mfd.care.virtue & \\textbf{0.09} & \\textbf{0.09} & \\textbf{0.10} & 0.02 & \\textbf{0.07} & \\textbf{0.09} & 0.08\\\\\n",
      " & mfd.authority.vice & \\textbf{-0.06} & -0.03 & -0.03 & -0.04 & -0.04 & -0.03 & -0.06\\\\\n",
      " & affiliation & \\textbf{0.07} & \\textbf{0.09} & \\textbf{0.10} & 0.06 & \\textbf{0.08} & \\textbf{0.07} & 0.07\\\\\n",
      "# column of interest: fairness\n",
      " & mfd.authority.vice & \\textbf{-0.06} & -0.04 & -0.04 & -0.03 & -0.05 & -0.04 & -0.04\\\\\n",
      " & relig & \\textbf{-0.06} & -0.03 & -0.05 & -0.01 & -0.05 & \\textbf{-0.06} & -0.02\\\\\n",
      " & mfd.sanctity.virtue & \\textbf{-0.07} & -0.04 & -0.05 & -0.01 & -0.06 & \\textbf{-0.06} & -0.02\\\\\n",
      "# column of interest: loyalty\n",
      " & socrefs & \\textbf{0.09} & \\textbf{0.13} & \\textbf{0.11} & \\textbf{0.16} & \\textbf{0.11} & \\textbf{0.10} & 0.09\\\\\n",
      " & friend & \\textbf{0.07} & \\textbf{0.06} & 0.06 & 0.07 & \\textbf{0.06} & 0.06 & 0.06\\\\\n",
      " & mfd.care.virtue & \\textbf{0.06} & 0.04 & 0.04 & 0.07 & 0.05 & 0.04 & 0.06\\\\\n",
      " & Affect & \\textbf{0.10} & \\textbf{0.10} & \\textbf{0.13} & \\textbf{0.21} & \\textbf{0.12} & \\textbf{0.11} & \\textbf{0.11}\\\\\n",
      " & affiliation & \\textbf{0.06} & \\textbf{0.10} & \\textbf{0.08} & \\textbf{0.11} & \\textbf{0.07} & 0.06 & 0.07\\\\\n",
      " & family & \\textbf{0.11} & \\textbf{0.12} & \\textbf{0.12} & 0.09 & \\textbf{0.11} & \\textbf{0.11} & 0.10\\\\\n",
      " & relig & \\textbf{0.12} & \\textbf{0.12} & \\textbf{0.13} & 0.09 & \\textbf{0.12} & \\textbf{0.12} & \\textbf{0.11}\\\\\n",
      " & mfd.sanctity.virtue & \\textbf{0.14} & \\textbf{0.10} & \\textbf{0.12} & 0.08 & \\textbf{0.13} & \\textbf{0.12} & \\textbf{0.12}\\\\\n",
      " & you & \\textbf{0.08} & \\textbf{0.10} & \\textbf{0.09} & \\textbf{0.15} & \\textbf{0.09} & \\textbf{0.10} & \\textbf{0.12}\\\\\n",
      " & Social & \\textbf{0.08} & \\textbf{0.12} & \\textbf{0.10} & \\textbf{0.17} & \\textbf{0.10} & \\textbf{0.11} & \\textbf{0.12}\\\\\n",
      "# column of interest: authority\n",
      " & socrefs & \\textbf{0.16} & \\textbf{0.15} & \\textbf{0.14} & \\textbf{0.19} & \\textbf{0.16} & \\textbf{0.13} & \\textbf{0.12}\\\\\n",
      " & pronoun & \\textbf{0.13} & \\textbf{0.11} & \\textbf{0.11} & \\textbf{0.18} & \\textbf{0.13} & \\textbf{0.12} & \\textbf{0.12}\\\\\n",
      " & friend & \\textbf{0.07} & \\textbf{0.06} & 0.05 & 0.08 & 0.06 & 0.04 & 0.07\\\\\n",
      " & mfd.care.virtue & \\textbf{0.09} & \\textbf{0.06} & \\textbf{0.06} & 0.10 & \\textbf{0.08} & \\textbf{0.06} & 0.08\\\\\n",
      " & Affect & \\textbf{0.15} & \\textbf{0.13} & \\textbf{0.13} & \\textbf{0.25} & \\textbf{0.16} & \\textbf{0.13} & \\textbf{0.15}\\\\\n",
      " & i & \\textbf{0.07} & \\textbf{0.07} & \\textbf{0.08} & \\textbf{0.12} & \\textbf{0.08} & \\textbf{0.08} & \\textbf{0.11}\\\\\n",
      " & affiliation & \\textbf{0.12} & \\textbf{0.11} & \\textbf{0.11} & \\textbf{0.14} & \\textbf{0.11} & \\textbf{0.09} & 0.10\\\\\n",
      " & prosocial & \\textbf{0.06} & \\textbf{0.07} & 0.05 & \\textbf{0.13} & \\textbf{0.07} & 0.06 & \\textbf{0.12}\\\\\n",
      " & family & \\textbf{0.16} & \\textbf{0.15} & \\textbf{0.17} & \\textbf{0.14} & \\textbf{0.15} & \\textbf{0.16} & \\textbf{0.14}\\\\\n",
      " & relig & \\textbf{0.16} & \\textbf{0.15} & \\textbf{0.15} & 0.06 & \\textbf{0.16} & \\textbf{0.16} & 0.09\\\\\n",
      " & mfd.sanctity.virtue & \\textbf{0.16} & \\textbf{0.13} & \\textbf{0.15} & 0.04 & \\textbf{0.15} & \\textbf{0.16} & 0.10\\\\\n",
      " & you & \\textbf{0.11} & \\textbf{0.11} & \\textbf{0.09} & \\textbf{0.19} & \\textbf{0.11} & \\textbf{0.09} & \\textbf{0.14}\\\\\n",
      " & Social & \\textbf{0.16} & \\textbf{0.14} & \\textbf{0.12} & \\textbf{0.17} & \\textbf{0.16} & \\textbf{0.12} & \\textbf{0.14}\\\\\n",
      "# column of interest: purity\n",
      " & we & \\textbf{0.07} & \\textbf{0.09} & \\textbf{0.08} & 0.06 & \\textbf{0.08} & \\textbf{0.06} & 0.02\\\\\n",
      " & socrefs & \\textbf{0.19} & \\textbf{0.20} & \\textbf{0.20} & \\textbf{0.19} & \\textbf{0.20} & \\textbf{0.19} & \\textbf{0.13}\\\\\n",
      " & pronoun & \\textbf{0.13} & \\textbf{0.11} & \\textbf{0.13} & \\textbf{0.17} & \\textbf{0.13} & \\textbf{0.14} & \\textbf{0.11}\\\\\n",
      " & friend & \\textbf{0.07} & \\textbf{0.07} & \\textbf{0.06} & 0.08 & \\textbf{0.07} & \\textbf{0.06} & 0.10\\\\\n",
      " & mfd.care.virtue & \\textbf{0.11} & \\textbf{0.09} & \\textbf{0.09} & 0.09 & \\textbf{0.11} & \\textbf{0.09} & 0.07\\\\\n",
      " & Affect & \\textbf{0.12} & \\textbf{0.12} & \\textbf{0.13} & \\textbf{0.20} & \\textbf{0.15} & \\textbf{0.11} & \\textbf{0.12}\\\\\n",
      " & i & \\textbf{0.06} & 0.04 & \\textbf{0.06} & \\textbf{0.11} & 0.05 & \\textbf{0.06} & \\textbf{0.11}\\\\\n",
      " & affiliation & \\textbf{0.15} & \\textbf{0.15} & \\textbf{0.15} & \\textbf{0.14} & \\textbf{0.14} & \\textbf{0.12} & 0.10\\\\\n",
      " & prosocial & \\textbf{0.06} & \\textbf{0.07} & 0.05 & \\textbf{0.12} & \\textbf{0.08} & \\textbf{0.06} & \\textbf{0.13}\\\\\n",
      " & family & \\textbf{0.15} & \\textbf{0.15} & \\textbf{0.17} & 0.10 & \\textbf{0.15} & \\textbf{0.15} & 0.10\\\\\n",
      " & relig & \\textbf{0.21} & \\textbf{0.21} & \\textbf{0.21} & \\textbf{0.11} & \\textbf{0.21} & \\textbf{0.22} & \\textbf{0.16}\\\\\n",
      " & mfd.sanctity.virtue & \\textbf{0.21} & \\textbf{0.19} & \\textbf{0.22} & \\textbf{0.11} & \\textbf{0.21} & \\textbf{0.22} & \\textbf{0.18}\\\\\n",
      " & mfd.sanctity.vice & \\textbf{-0.06} & 0.01 & 0.02 & -0.02 & 0.00 & -0.02 & -0.05\\\\\n",
      " & you & \\textbf{0.13} & \\textbf{0.13} & \\textbf{0.11} & \\textbf{0.17} & \\textbf{0.13} & \\textbf{0.12} & \\textbf{0.15}\\\\\n",
      " & Social & \\textbf{0.19} & \\textbf{0.20} & \\textbf{0.18} & \\textbf{0.18} & \\textbf{0.20} & \\textbf{0.18} & \\textbf{0.16}\\\\\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "for col_of_interest in [\n",
    "    \"care\",\n",
    "    \"fairness\",\n",
    "    \"loyalty\",\n",
    "    \"authority\",\n",
    "    \"purity\",\n",
    "]:\n",
    "\n",
    "    categories = []\n",
    "    llms = []\n",
    "    prompts = []\n",
    "    pearson_rs = []\n",
    "    p_values = []\n",
    "\n",
    "    threshold_based_on_bonferroni = 0.05 / len(facebook_columns) / 5\n",
    "\n",
    "    for key, value in all_data_dictionaries.items():\n",
    "        for column in facebook_columns:\n",
    "            categories.append(column)\n",
    "            llms.append(key[0])\n",
    "            prompts.append(key[1])\n",
    "\n",
    "            pearson_r, p_value = pearsonr(\n",
    "                value.dropna(subset=[f\"z.{col_of_interest}\", column])[\n",
    "                    f\"z.{col_of_interest}\"\n",
    "                ],\n",
    "                value.dropna(subset=[f\"z.{col_of_interest}\", column])[column],\n",
    "            )\n",
    "            pearson_rs.append(pearson_r)\n",
    "            p_values.append(p_value)\n",
    "\n",
    "    summary_df = pd.DataFrame(\n",
    "        {\n",
    "            \"category\": categories,\n",
    "            \"llm\": llms,\n",
    "            \"prompt\": prompts,\n",
    "            \"pearson_r\": pearson_rs,\n",
    "            \"p_value\": p_values,\n",
    "        }\n",
    "    )\n",
    "    summary_df[\"significant\"] = summary_df[\"p_value\"] < threshold_based_on_bonferroni\n",
    "\n",
    "    print(\"# column of interest:\", col_of_interest)\n",
    "\n",
    "    for category in summary_df[\n",
    "        (summary_df[\"significant\"]) & (summary_df[\"llm\"] == \"original\")\n",
    "    ][\"category\"].unique():\n",
    "        print(f\" & {category} & \", end=\"\")\n",
    "        original_values = summary_df[\n",
    "            (summary_df[\"category\"] == category) & (summary_df[\"llm\"] == \"original\")\n",
    "        ]\n",
    "        is_significant = original_values[\"significant\"].values[0]\n",
    "        if is_significant:\n",
    "            print(\n",
    "                f\"\\\\textbf{{{original_values['pearson_r'].values[0]:.2f}}}\",\n",
    "                end=\"\",\n",
    "            )\n",
    "        else:\n",
    "            print(\n",
    "                f\"{original_values['pearson_r'].values[0]:.2f}\",\n",
    "                end=\"\",\n",
    "            )\n",
    "        for prompt in [\"rephrase\", \"syntax_grammar\"]:\n",
    "            for llm in [\"gemini\", \"gpt\", \"llama\"]:\n",
    "                values = summary_df[\n",
    "                    (summary_df[\"category\"] == category)\n",
    "                    & (summary_df[\"llm\"] == prompt)\n",
    "                    & (summary_df[\"prompt\"] == llm)\n",
    "                ]\n",
    "                is_significant = values[\"significant\"].values[0]\n",
    "                if is_significant:\n",
    "                    print(\n",
    "                        f\" & \\\\textbf{{{values['pearson_r'].values[0]:.2f}}}\",\n",
    "                        end=\"\",\n",
    "                    )\n",
    "                else:\n",
    "                    print(\n",
    "                        f\" & {values['pearson_r'].values[0]:.2f}\",\n",
    "                        end=\"\",\n",
    "                    )\n",
    "        print(\"\\\\\\\\\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Political"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_path = \"political/with_dictionaries_both/\"\n",
    "all_files = os.listdir(parent_path)\n",
    "original_df = pd.read_csv(\n",
    "    os.path.join(parent_path, [file for file in all_files if \"clean_data\" in file][0])\n",
    ")\n",
    "syntax_grammar_llama = pd.read_csv(\n",
    "    os.path.join(\n",
    "        parent_path, [file for file in all_files if \"syntax_grammar_llama\" in file][0]\n",
    "    )\n",
    ")\n",
    "rephrase_llama = pd.read_csv(\n",
    "    os.path.join(\n",
    "        parent_path, [file for file in all_files if \"rephrase_llama\" in file][0]\n",
    "    )\n",
    ")\n",
    "syntax_grammar_gpt = pd.read_csv(\n",
    "    os.path.join(\n",
    "        parent_path, [file for file in all_files if \"syntax_grammar_gpt\" in file][0]\n",
    "    )\n",
    ")\n",
    "rephrase_gpt = pd.read_csv(\n",
    "    os.path.join(parent_path, [file for file in all_files if \"rephrase_gpt\" in file][0])\n",
    ")\n",
    "syntax_grammar_gemini = pd.read_csv(\n",
    "    os.path.join(\n",
    "        parent_path, [file for file in all_files if \"syntax_grammar_gemini\" in file][0]\n",
    "    )\n",
    ")\n",
    "rephrase_gemini = pd.read_csv(\n",
    "    os.path.join(\n",
    "        parent_path, [file for file in all_files if \"rephrase_gemini\" in file][0]\n",
    "    )\n",
    ")\n",
    "\n",
    "all_data_dictionaries = {\n",
    "    (\"original\", \"-\"): original_df,\n",
    "    (\"syntax_grammar\", \"llama\"): syntax_grammar_llama,\n",
    "    (\"rephrase\", \"llama\"): rephrase_llama,\n",
    "    (\"syntax_grammar\", \"gpt\"): syntax_grammar_gpt,\n",
    "    (\"rephrase\", \"gpt\"): rephrase_gpt,\n",
    "    (\"syntax_grammar\", \"gemini\"): syntax_grammar_gemini,\n",
    "    (\"rephrase\", \"gemini\"): rephrase_gemini,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in political_columns:\n",
    "    if col not in original_df.columns:\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = []\n",
    "llms = []\n",
    "prompts = []\n",
    "means_democrat = []\n",
    "means_republican = []\n",
    "stats = []\n",
    "p_values = []\n",
    "\n",
    "threshold_based_on_bonferroni = 0.05 / len(political_columns)\n",
    "\n",
    "for key, value in all_data_dictionaries.items():\n",
    "    for column in political_columns:\n",
    "        categories.append(column)\n",
    "        llms.append(key[0])\n",
    "        prompts.append(key[1])\n",
    "        means_democrat.append(value[value[\"party\"] == \"D\"][column].mean())\n",
    "        means_republican.append(value[value[\"party\"] == \"R\"][column].mean())\n",
    "        t_stat, p_value = ttest_ind(\n",
    "            value[value[\"party\"] == \"D\"][column],\n",
    "            value[value[\"party\"] == \"R\"][column],\n",
    "        )\n",
    "        stats.append(t_stat)\n",
    "        p_values.append(p_value)\n",
    "\n",
    "summary_df = pd.DataFrame(\n",
    "    {\n",
    "        \"category\": categories,\n",
    "        \"llm\": llms,\n",
    "        \"prompt\": prompts,\n",
    "        \"mean_democrat\": means_democrat,\n",
    "        \"mean_republican\": means_republican,\n",
    "        \"t_stat\": stats,\n",
    "        \"p_value\": p_values,\n",
    "    }\n",
    ")\n",
    "summary_df[\"significant\"] = summary_df[\"p_value\"] < threshold_based_on_bonferroni\n",
    "# summary_df = summary_df[summary_df[\"significant\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mfd.loyalty.virtue & \\textbf{0.02} & \\textbf{0.02} & \\textbf{0.03} & \\textbf{0.02} & \\textbf{0.03} & \\textbf{0.03} & 0.03 & 0.03 & \\textbf{0.02} & \\textbf{0.02} & \\textbf{0.03} & \\textbf{0.03} & \\textbf{0.03} & \\textbf{0.02} & \\\\\n",
      "emo_anx & \\textbf{0.07} & \\textbf{0.06} & \\textbf{0.08} & \\textbf{0.05} & 0.07 & 0.07 & 0.06 & 0.06 & \\textbf{0.07} & \\textbf{0.06} & 0.08 & 0.07 & \\textbf{0.07} & \\textbf{0.06} & \\\\\n",
      "adverb & \\textbf{3.41} & \\textbf{3.71} & 1.98 & 2.07 & \\textbf{2.22} & \\textbf{2.35} & \\textbf{2.31} & \\textbf{2.45} & \\textbf{3.06} & \\textbf{3.28} & \\textbf{2.38} & \\textbf{2.52} & \\textbf{2.82} & \\textbf{3.04} & \\\\\n",
      "emo_neg & \\textbf{0.31} & \\textbf{0.27} & 0.31 & 0.28 & 0.26 & 0.25 & 0.25 & 0.25 & \\textbf{0.30} & \\textbf{0.26} & 0.29 & 0.27 & 0.30 & 0.27 & \\\\\n",
      "i & \\textbf{1.64} & \\textbf{1.75} & 1.16 & 1.27 & 1.78 & 1.88 & 1.88 & 2.00 & \\textbf{1.66} & \\textbf{1.79} & 1.63 & 1.68 & 1.73 & 1.82 & \\\\\n",
      "cogproc & \\textbf{9.28} & \\textbf{9.58} & \\textbf{8.32} & \\textbf{8.77} & \\textbf{8.08} & \\textbf{8.54} & \\textbf{8.87} & \\textbf{9.43} & \\textbf{9.14} & \\textbf{9.48} & \\textbf{8.22} & \\textbf{8.64} & \\textbf{9.01} & \\textbf{9.41} & \\\\\n",
      "certitude & \\textbf{0.49} & \\textbf{0.56} & 0.22 & 0.24 & \\textbf{0.21} & \\textbf{0.24} & \\textbf{0.23} & \\textbf{0.27} & \\textbf{0.43} & \\textbf{0.48} & \\textbf{0.27} & \\textbf{0.30} & \\textbf{0.37} & \\textbf{0.41} & \\\\\n"
     ]
    }
   ],
   "source": [
    "for category in summary_df[\n",
    "    (summary_df[\"significant\"]) & (summary_df[\"llm\"] == \"original\")\n",
    "][\"category\"].unique():\n",
    "    print(f\"{category} & \", end=\"\")\n",
    "    original_values = summary_df[\n",
    "        (summary_df[\"category\"] == category) & (summary_df[\"llm\"] == \"original\")\n",
    "    ]\n",
    "    is_significant = original_values[\"significant\"].values[0]\n",
    "    if is_significant:\n",
    "        print(\n",
    "            f\"\\\\textbf{{{original_values['mean_democrat'].values[0]:.2f}}} & \\\\textbf{{{original_values['mean_republican'].values[0]:.2f}}} & \",\n",
    "            end=\"\",\n",
    "        )\n",
    "    else:\n",
    "        print(\n",
    "            f\"{original_values['mean_democrat'].values[0]:.2f} & {original_values['mean_republican'].values[0]:.2f} & \",\n",
    "            end=\"\",\n",
    "        )\n",
    "    for prompt in [\"rephrase\", \"syntax_grammar\"]:\n",
    "        for llm in [\"gemini\", \"gpt\", \"llama\"]:\n",
    "            values = summary_df[\n",
    "                (summary_df[\"category\"] == category)\n",
    "                & (summary_df[\"llm\"] == prompt)\n",
    "                & (summary_df[\"prompt\"] == llm)\n",
    "            ]\n",
    "            is_significant = values[\"significant\"].values[0]\n",
    "            if is_significant:\n",
    "                print(\n",
    "                    f\"\\\\textbf{{{values['mean_democrat'].values[0]:.2f}}} & \\\\textbf{{{values['mean_republican'].values[0]:.2f}}} & \",\n",
    "                    end=\"\",\n",
    "                )\n",
    "            else:\n",
    "                print(\n",
    "                    f\"{values['mean_democrat'].values[0]:.2f} & {values['mean_republican'].values[0]:.2f} & \",\n",
    "                    end=\"\",\n",
    "                )\n",
    "    print(\"\\\\\\\\\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_path = \"political/with_dictionaries_both/\"\n",
    "all_files = os.listdir(parent_path)\n",
    "original_df = pd.read_csv(\n",
    "    os.path.join(parent_path, [file for file in all_files if \"clean_data\" in file][0])\n",
    ")\n",
    "syntax_grammar_llama = pd.read_csv(\n",
    "    os.path.join(\n",
    "        parent_path, [file for file in all_files if \"syntax_grammar_llama\" in file][0]\n",
    "    )\n",
    ")\n",
    "rephrase_llama = pd.read_csv(\n",
    "    os.path.join(\n",
    "        parent_path, [file for file in all_files if \"rephrase_llama\" in file][0]\n",
    "    )\n",
    ")\n",
    "syntax_grammar_gpt = pd.read_csv(\n",
    "    os.path.join(\n",
    "        parent_path, [file for file in all_files if \"syntax_grammar_gpt\" in file][0]\n",
    "    )\n",
    ")\n",
    "rephrase_gpt = pd.read_csv(\n",
    "    os.path.join(parent_path, [file for file in all_files if \"rephrase_gpt\" in file][0])\n",
    ")\n",
    "syntax_grammar_gemini = pd.read_csv(\n",
    "    os.path.join(\n",
    "        parent_path, [file for file in all_files if \"syntax_grammar_gemini\" in file][0]\n",
    "    )\n",
    ")\n",
    "rephrase_gemini = pd.read_csv(\n",
    "    os.path.join(\n",
    "        parent_path, [file for file in all_files if \"rephrase_gemini\" in file][0]\n",
    "    )\n",
    ")\n",
    "\n",
    "all_data_dictionaries = {\n",
    "    (\"original\", \"-\"): original_df,\n",
    "    (\"syntax_grammar\", \"llama\"): syntax_grammar_llama,\n",
    "    (\"rephrase\", \"llama\"): rephrase_llama,\n",
    "    (\"syntax_grammar\", \"gpt\"): syntax_grammar_gpt,\n",
    "    (\"rephrase\", \"gpt\"): rephrase_gpt,\n",
    "    (\"syntax_grammar\", \"gemini\"): syntax_grammar_gemini,\n",
    "    (\"rephrase\", \"gemini\"): rephrase_gemini,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in gender_columns:\n",
    "    if col not in original_df.columns:\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = []\n",
    "llms = []\n",
    "prompts = []\n",
    "means_males = []\n",
    "means_females = []\n",
    "stats = []\n",
    "p_values = []\n",
    "\n",
    "threshold_based_on_bonferroni = 0.05 / len(gender_columns)\n",
    "\n",
    "for key, value in all_data_dictionaries.items():\n",
    "    for column in gender_columns:\n",
    "        categories.append(column)\n",
    "        llms.append(key[0])\n",
    "        prompts.append(key[1])\n",
    "        means_males.append(value[value[\"gender\"] == \"M\"][column].mean())\n",
    "        means_females.append(value[value[\"gender\"] == \"F\"][column].mean())\n",
    "        t_stat, p_value = ttest_ind(\n",
    "            value[value[\"gender\"] == \"M\"][column],\n",
    "            value[value[\"gender\"] == \"F\"][column],\n",
    "        )\n",
    "        stats.append(t_stat)\n",
    "        p_values.append(p_value)\n",
    "\n",
    "summary_df = pd.DataFrame(\n",
    "    {\n",
    "        \"category\": categories,\n",
    "        \"llm\": llms,\n",
    "        \"prompt\": prompts,\n",
    "        \"mean_males\": means_males,\n",
    "        \"mean_females\": means_females,\n",
    "        \"t_stat\": stats,\n",
    "        \"p_value\": p_values,\n",
    "    }\n",
    ")\n",
    "summary_df[\"significant\"] = summary_df[\"p_value\"] < threshold_based_on_bonferroni\n",
    "# summary_df = summary_df[summary_df[\"significant\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "article & \\textbf{8.52} & \\textbf{8.01} & \\textbf{8.72} & \\textbf{8.20} & \\textbf{8.45} & \\textbf{7.99} & \\textbf{8.98} & \\textbf{8.41} & \\textbf{8.60} & \\textbf{8.01} & \\textbf{8.79} & \\textbf{8.31} & \\textbf{8.75} & \\textbf{8.17} & \\\\\n",
      "social & \\textbf{7.51} & \\textbf{8.26} & \\textbf{6.27} & \\textbf{7.01} & \\textbf{6.14} & \\textbf{6.69} & \\textbf{7.52} & \\textbf{8.06} & \\textbf{7.18} & \\textbf{8.01} & \\textbf{5.97} & \\textbf{6.55} & \\textbf{7.43} & \\textbf{8.16} & \\\\\n",
      "emo_anx & \\textbf{0.06} & \\textbf{0.07} & \\textbf{0.05} & \\textbf{0.08} & \\textbf{0.06} & \\textbf{0.08} & \\textbf{0.05} & \\textbf{0.07} & \\textbf{0.06} & \\textbf{0.07} & \\textbf{0.07} & \\textbf{0.08} & \\textbf{0.06} & \\textbf{0.07} & \\\\\n",
      "i & \\textbf{1.65} & \\textbf{1.76} & 1.20 & 1.23 & 1.79 & 1.88 & 1.91 & 1.97 & \\textbf{1.66} & \\textbf{1.80} & \\textbf{1.62} & \\textbf{1.70} & 1.75 & 1.81 & \\\\\n",
      "emo_neg & \\textbf{0.28} & \\textbf{0.30} & 0.30 & 0.30 & 0.25 & 0.27 & 0.24 & 0.26 & 0.27 & 0.29 & \\textbf{0.27} & \\textbf{0.29} & 0.28 & 0.29 & \\\\\n",
      "affect & \\textbf{4.62} & \\textbf{4.78} & 5.64 & 5.80 & \\textbf{5.70} & \\textbf{5.96} & \\textbf{5.92} & \\textbf{6.08} & \\textbf{4.70} & \\textbf{4.87} & \\textbf{5.14} & \\textbf{5.37} & \\textbf{5.09} & \\textbf{5.25} & \\\\\n",
      "tentat & \\textbf{1.41} & \\textbf{1.30} & \\textbf{0.89} & \\textbf{0.83} & \\textbf{0.91} & \\textbf{0.80} & \\textbf{0.95} & \\textbf{0.88} & \\textbf{1.35} & \\textbf{1.21} & \\textbf{1.10} & \\textbf{0.99} & \\textbf{1.17} & \\textbf{1.08} & \\\\\n",
      "swear & \\textbf{0.01} & \\textbf{0.00} & 0.00 & 0.00 & 0.00 & 0.00 & 0.00 & 0.00 & \\textbf{0.01} & \\textbf{0.00} & 0.00 & 0.00 & 0.00 & 0.00 & \\\\\n",
      "cogproc & \\textbf{9.50} & \\textbf{9.33} & \\textbf{8.69} & \\textbf{8.34} & \\textbf{8.52} & \\textbf{8.02} & \\textbf{9.27} & \\textbf{8.97} & \\textbf{9.48} & \\textbf{9.07} & \\textbf{8.60} & \\textbf{8.19} & \\textbf{9.37} & \\textbf{8.99} & \\\\\n"
     ]
    }
   ],
   "source": [
    "for category in summary_df[\n",
    "    (summary_df[\"significant\"]) & (summary_df[\"llm\"] == \"original\")\n",
    "][\"category\"].unique():\n",
    "    print(f\"{category} & \", end=\"\")\n",
    "    original_values = summary_df[\n",
    "        (summary_df[\"category\"] == category) & (summary_df[\"llm\"] == \"original\")\n",
    "    ]\n",
    "    is_significant = original_values[\"significant\"].values[0]\n",
    "    if is_significant:\n",
    "        print(\n",
    "            f\"\\\\textbf{{{original_values['mean_males'].values[0]:.2f}}} & \\\\textbf{{{original_values['mean_females'].values[0]:.2f}}} & \",\n",
    "            end=\"\",\n",
    "        )\n",
    "    else:\n",
    "        print(\n",
    "            f\"{original_values['mean_males'].values[0]:.2f} & {original_values['mean_females'].values[0]:.2f} & \",\n",
    "            end=\"\",\n",
    "        )\n",
    "    for prompt in [\"rephrase\", \"syntax_grammar\"]:\n",
    "        for llm in [\"gemini\", \"gpt\", \"llama\"]:\n",
    "            values = summary_df[\n",
    "                (summary_df[\"category\"] == category)\n",
    "                & (summary_df[\"llm\"] == prompt)\n",
    "                & (summary_df[\"prompt\"] == llm)\n",
    "            ]\n",
    "            is_significant = values[\"significant\"].values[0]\n",
    "            if is_significant:\n",
    "                print(\n",
    "                    f\"\\\\textbf{{{values['mean_males'].values[0]:.2f}}} & \\\\textbf{{{values['mean_females'].values[0]:.2f}}} & \",\n",
    "                    end=\"\",\n",
    "                )\n",
    "            else:\n",
    "                print(\n",
    "                    f\"{values['mean_males'].values[0]:.2f} & {values['mean_females'].values[0]:.2f} & \",\n",
    "                    end=\"\",\n",
    "                )\n",
    "    print(\"\\\\\\\\\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_path = \"political/with_dictionaries_both/\"\n",
    "all_files = os.listdir(parent_path)\n",
    "original_df = pd.read_csv(\n",
    "    os.path.join(parent_path, [file for file in all_files if \"clean_data\" in file][0])\n",
    ")\n",
    "syntax_grammar_llama = pd.read_csv(\n",
    "    os.path.join(\n",
    "        parent_path, [file for file in all_files if \"syntax_grammar_llama\" in file][0]\n",
    "    )\n",
    ")\n",
    "rephrase_llama = pd.read_csv(\n",
    "    os.path.join(\n",
    "        parent_path, [file for file in all_files if \"rephrase_llama\" in file][0]\n",
    "    )\n",
    ")\n",
    "syntax_grammar_gpt = pd.read_csv(\n",
    "    os.path.join(\n",
    "        parent_path, [file for file in all_files if \"syntax_grammar_gpt\" in file][0]\n",
    "    )\n",
    ")\n",
    "rephrase_gpt = pd.read_csv(\n",
    "    os.path.join(parent_path, [file for file in all_files if \"rephrase_gpt\" in file][0])\n",
    ")\n",
    "syntax_grammar_gemini = pd.read_csv(\n",
    "    os.path.join(\n",
    "        parent_path, [file for file in all_files if \"syntax_grammar_gemini\" in file][0]\n",
    "    )\n",
    ")\n",
    "rephrase_gemini = pd.read_csv(\n",
    "    os.path.join(\n",
    "        parent_path, [file for file in all_files if \"rephrase_gemini\" in file][0]\n",
    "    )\n",
    ")\n",
    "\n",
    "main_data_political = pd.read_csv(\"political/political_data.csv\")\n",
    "main_data_political_speaker_id_to_age = dict(\n",
    "    zip(main_data_political[\"speakerid\"], main_data_political[\"age\"])\n",
    ")\n",
    "\n",
    "original_df[\"age\"] = original_df[\"speakerid\"].map(main_data_political_speaker_id_to_age)\n",
    "syntax_grammar_llama[\"age\"] = syntax_grammar_llama[\"speakerid\"].map(\n",
    "    main_data_political_speaker_id_to_age\n",
    ")\n",
    "rephrase_llama[\"age\"] = rephrase_llama[\"speakerid\"].map(\n",
    "    main_data_political_speaker_id_to_age\n",
    ")\n",
    "syntax_grammar_gpt[\"age\"] = syntax_grammar_gpt[\"speakerid\"].map(\n",
    "    main_data_political_speaker_id_to_age\n",
    ")\n",
    "rephrase_gpt[\"age\"] = rephrase_gpt[\"speakerid\"].map(\n",
    "    main_data_political_speaker_id_to_age\n",
    ")\n",
    "syntax_grammar_gemini[\"age\"] = syntax_grammar_gemini[\"speakerid\"].map(\n",
    "    main_data_political_speaker_id_to_age\n",
    ")\n",
    "rephrase_gemini[\"age\"] = rephrase_gemini[\"speakerid\"].map(\n",
    "    main_data_political_speaker_id_to_age\n",
    ")\n",
    "\n",
    "\n",
    "all_data_dictionaries = {\n",
    "    (\"original\", \"-\"): original_df,\n",
    "    (\"syntax_grammar\", \"llama\"): syntax_grammar_llama,\n",
    "    (\"rephrase\", \"llama\"): rephrase_llama,\n",
    "    (\"syntax_grammar\", \"gpt\"): syntax_grammar_gpt,\n",
    "    (\"rephrase\", \"gpt\"): rephrase_gpt,\n",
    "    (\"syntax_grammar\", \"gemini\"): syntax_grammar_gemini,\n",
    "    (\"rephrase\", \"gemini\"): rephrase_gemini,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in age_columns:\n",
    "    if col not in original_df.columns:\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "categories = []\n",
    "llms = []\n",
    "prompts = []\n",
    "pearson_rs = []\n",
    "p_values = []\n",
    "\n",
    "threshold_based_on_bonferroni = 0.05 / len(age_columns)\n",
    "\n",
    "for key, value in all_data_dictionaries.items():\n",
    "    for column in age_columns:\n",
    "        categories.append(column)\n",
    "        llms.append(key[0])\n",
    "        prompts.append(key[1])\n",
    "        pearson_r, p_value = pearsonr(\n",
    "            value[\"age\"],\n",
    "            value[column],\n",
    "        )\n",
    "        pearson_rs.append(pearson_r)\n",
    "        p_values.append(p_value)\n",
    "\n",
    "\n",
    "summary_df = pd.DataFrame(\n",
    "    {\n",
    "        \"category\": categories,\n",
    "        \"llm\": llms,\n",
    "        \"prompt\": prompts,\n",
    "        \"pearson_r\": pearson_rs,\n",
    "        \"p_value\": p_values,\n",
    "    }\n",
    ")\n",
    "summary_df[\"significant\"] = summary_df[\"p_value\"] < threshold_based_on_bonferroni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "focusfuture & \\textbf{-0.09} & -0.05 & \\textbf{-0.09} & \\textbf{-0.10} & -0.07 & \\textbf{-0.08} & \\textbf{-0.09}\\\\\n"
     ]
    }
   ],
   "source": [
    "for category in summary_df[\n",
    "    (summary_df[\"significant\"]) & (summary_df[\"llm\"] == \"original\")\n",
    "][\"category\"].unique():\n",
    "    print(f\"{category} & \", end=\"\")\n",
    "    original_values = summary_df[\n",
    "        (summary_df[\"category\"] == category) & (summary_df[\"llm\"] == \"original\")\n",
    "    ]\n",
    "    is_significant = original_values[\"significant\"].values[0]\n",
    "    if is_significant:\n",
    "        print(\n",
    "            f\"\\\\textbf{{{original_values['pearson_r'].values[0]:.2f}}}\",\n",
    "            end=\"\",\n",
    "        )\n",
    "    else:\n",
    "        print(\n",
    "            f\"{original_values['pearson_r'].values[0]:.2f}\",\n",
    "            end=\"\",\n",
    "        )\n",
    "    for prompt in [\"rephrase\", \"syntax_grammar\"]:\n",
    "        for llm in [\"gemini\", \"gpt\", \"llama\"]:\n",
    "            values = summary_df[\n",
    "                (summary_df[\"category\"] == category)\n",
    "                & (summary_df[\"llm\"] == prompt)\n",
    "                & (summary_df[\"prompt\"] == llm)\n",
    "            ]\n",
    "            is_significant = values[\"significant\"].values[0]\n",
    "            if is_significant:\n",
    "                print(\n",
    "                    f\" & \\\\textbf{{{values['pearson_r'].values[0]:.2f}}}\",\n",
    "                    end=\"\",\n",
    "                )\n",
    "            else:\n",
    "                print(\n",
    "                    f\" & {values['pearson_r'].values[0]:.2f}\",\n",
    "                    end=\"\",\n",
    "                )\n",
    "    print(\"\\\\\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
