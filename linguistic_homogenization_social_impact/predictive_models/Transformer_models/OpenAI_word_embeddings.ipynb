{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aneko\\AppData\\Local\\Temp\\ipykernel_26968\\3765745001.py:103: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  results_df.to_csv(results_output_path, index=False, quoting=csv.QUOTE_NONNUMERIC, line_terminator='\\n')\n",
      "C:\\Users\\aneko\\AppData\\Local\\Temp\\ipykernel_26968\\3765745001.py:106: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  embeddings_df.to_csv(embeddings_output_path, index=False, quoting=csv.QUOTE_NONNUMERIC, line_terminator='\\n')\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "import openai\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge  \n",
    "from sklearn.metrics import r2_score, make_scorer\n",
    "import tiktoken\n",
    "from openai.embeddings_utils import get_embedding\n",
    "import os\n",
    "from sklearn.model_selection import KFold, cross_val_predict\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Embedding model parameters\n",
    "embedding_model = \"text-embedding-ada-002\"\n",
    "embedding_encoding = \"cl100k_base\"  # This the encoding for text-embedding-ada-002\n",
    "max_tokens = 8000  # The maximum for text-embedding-ada-002 is 8191\n",
    "input_datapath = \"IntroBigFiveessays_anon/essays_anon_full.csv\"\n",
    "embeddings_output_path = \"embeddings.csv\"\n",
    "results_output_path = \"output_results.csv\"\n",
    "\n",
    "# Read data from CSV file\n",
    "df = pd.read_csv(input_datapath)\n",
    "df = df.dropna()\n",
    "\n",
    "# Initialize encoding\n",
    "encoding = tiktoken.get_encoding(embedding_encoding)\n",
    "\n",
    "# Truncate long texts and calculate token count\n",
    "df[\"n_tokens\"] = df[\"text\"].apply(lambda x: len(encoding.encode(x)))\n",
    "# Omit rows where text is too long to embed\n",
    "df = df[df[\"n_tokens\"] <= max_tokens]\n",
    "# Get embeddings\n",
    "df[\"embedding\"] = df[\"text\"].apply(lambda x: get_embedding(x, engine=embedding_model))\n",
    "\n",
    "# # Tokenize and truncate the text to keep only the first `max_tokens` tokens\n",
    "# def tokenize_and_truncate(text, encoding, max_tokens=8000):\n",
    "#     encoded_text = encoding.encode(text)\n",
    "#     truncated_tokens = encoded_text[:max_tokens]\n",
    "#     truncated_text = ','.join(str(token) for token in truncated_tokens)\n",
    "#     return truncated_text\n",
    "\n",
    "# # Truncate the text to the maximum number of tokens\n",
    "# df[\"truncated_tokenized_text\"] = df[\"text\"].apply(lambda x: tokenize_and_truncate(x, encoding, max_tokens))\n",
    "\n",
    "# # Calculate the number of tokens in the truncated text\n",
    "# df[\"n_tokens\"] = df[\"truncated_tokenized_text\"].apply(lambda x: len(x.split(',')))\n",
    "\n",
    "# # Get embeddings for the truncated text\n",
    "# df[\"embedding\"] = df[\"truncated_tokenized_text\"].apply(lambda x: get_embedding(x, engine=embedding_model))\n",
    "\n",
    "# Save embeddings, AUTHID, text, and n_tokens to a separate CSV file\n",
    "# embeddings_df = df[['#AUTHID', 'text','truncated_tokenized_text', 'n_tokens', 'embedding']]\n",
    "\n",
    "# Save embeddings as a NumPy array\n",
    "# Extract embeddings and auth ids\n",
    "auth_ids = df['#AUTHID'].to_numpy()\n",
    "embeddings = np.vstack(df['embedding'].values)\n",
    "# Save to .npz file\n",
    "np.savez('embeddings.npz', auth_ids=auth_ids, embeddings=embeddings)\n",
    "\n",
    "\n",
    "# # load the embeddings\n",
    "# with np.load('embeddings.npz') as data:\n",
    "#     embeddings = data['arr_0']\n",
    "\n",
    "# Prepare data for regression\n",
    "X = np.vstack(df[\"embedding\"].apply(np.array).values)\n",
    "y = df[['zEXT', 'zNEU', 'zAGR', 'zCON', 'zOPN']].values\n",
    "\n",
    "# Initialize Ridge regression model\n",
    "reg_model = Ridge()\n",
    "\n",
    "# Define 5-fold cross-validation\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "cv_r2_scores = {}\n",
    "# Dictionary to store cv predictions\n",
    "cv_predictions = {}\n",
    "\n",
    "# Calculate cross-validation predictions and R^2 scores for each personality trait\n",
    "for i, trait in enumerate(['zEXT', 'zNEU', 'zAGR', 'zCON', 'zOPN']):\n",
    "    # Get cross-validated predictions\n",
    "    predictions = cross_val_predict(reg_model, X, y[:, i], cv=cv)\n",
    "    # Calculate R^2 score\n",
    "    r2_score_cv = r2_score(y[:, i], predictions)\n",
    "    # Store results\n",
    "    cv_r2_scores[f'cv_r2_score_{trait}'] = r2_score_cv\n",
    "    cv_predictions[f'cv_pred_{trait}'] = predictions\n",
    "\n",
    "# Add R^2 scores to DataFrame\n",
    "for trait, score in cv_r2_scores.items():\n",
    "    df[trait] = score\n",
    "\n",
    "# Add predictions to DataFrame\n",
    "for trait, preds in cv_predictions.items():\n",
    "    df[trait] = preds\n",
    "\n",
    "# Save results to CSV file\n",
    "results_df = df[['#AUTHID', 'text', 'n_tokens', 'zEXT', 'zNEU', 'zAGR', 'zCON', 'zOPN'] + [f'cv_r2_score_{trait}' for trait in ['zEXT', 'zNEU', 'zAGR', 'zCON', 'zOPN']] + [f'cv_pred_{trait}' for trait in ['zEXT', 'zNEU', 'zAGR', 'zCON', 'zOPN']]]\n",
    "results_df.to_csv(results_output_path, index=False, quoting=csv.QUOTE_NONNUMERIC, line_terminator='\\n')\n",
    "\n",
    "embeddings_df = df[['#AUTHID', 'text', 'n_tokens', 'embedding']]\n",
    "embeddings_df.to_csv(embeddings_output_path, index=False, quoting=csv.QUOTE_NONNUMERIC, line_terminator='\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Scores on Full Dataset:\n",
      "zEXT: 0.20286945750828544\n",
      "zNEU: 0.19291191932268892\n",
      "zAGR: 0.16807171266611753\n",
      "zCON: 0.1842493948764451\n",
      "zOPN: 0.26487599614806734\n",
      "R^2 Scores on Test Data (80-20 split):\n",
      "zEXT: 0.0850096978541458\n",
      "zNEU: 0.02329294286956285\n",
      "zAGR: 0.02776647955763334\n",
      "zCON: 0.028616450998607768\n",
      "zOPN: 0.14848491251035767\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge  \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Load embeddings and auth_ids from NPZ file\n",
    "with np.load('embeddings.npz', allow_pickle=True) as data:\n",
    "    auth_ids = data['auth_ids']\n",
    "    embeddings = data['embeddings']\n",
    "\n",
    "# Convert embeddings to a list of lists (if not already in that format)\n",
    "embeddings = [embedding.tolist() for embedding in embeddings]\n",
    "\n",
    "# Create a DataFrame from the loaded data\n",
    "df_embeddings = pd.DataFrame({'#AUTHID': auth_ids, 'embedding': embeddings})\n",
    "\n",
    "\n",
    "# df_embeddings.to_csv('output_with_embeddings.csv', index=False)\n",
    "\n",
    "\n",
    "input_datapath = \"IntroBigFiveessays_anon/essays_anon_full.csv\"\n",
    "# Read data from CSV file\n",
    "df = pd.read_csv(input_datapath)\n",
    "df = df.dropna()\n",
    "\n",
    "# Merge the dataframes on '#AUTHID'\n",
    "merged_df = pd.merge(df, df_embeddings, on='#AUTHID')\n",
    "\n",
    "# # Check if the merge is successful\n",
    "# print(merged_df.head())\n",
    "\n",
    "X = np.vstack(merged_df[\"embedding\"].apply(np.array).values)\n",
    "y = merged_df[['zEXT', 'zNEU', 'zAGR', 'zCON', 'zOPN']].values\n",
    "\n",
    "# Create linear regression model\n",
    "# model = LinearRegression()\n",
    "model = Ridge()\n",
    "# Train on full dataset\n",
    "model.fit(X, y)\n",
    "full_dataset_predictions = model.predict(X)\n",
    "\n",
    "# Calculate and print the R^2 score for each trait on the full dataset\n",
    "print(\"R^2 Scores on Full Dataset:\")\n",
    "for i, trait in enumerate(['zEXT', 'zNEU', 'zAGR', 'zCON', 'zOPN']):\n",
    "    print(f'{trait}: {r2_score(y[:, i], full_dataset_predictions[:, i])}')\n",
    "\n",
    "# Split the data into train and test sets (80-20 split)\n",
    "train_df, test_df = train_test_split(merged_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Extract embeddings and personality traits for training and testing\n",
    "X_train = np.vstack(train_df[\"embedding\"].apply(np.array).values)\n",
    "y_train = train_df[['zEXT', 'zNEU', 'zAGR', 'zCON', 'zOPN']].values\n",
    "\n",
    "X_test = np.vstack(test_df[\"embedding\"].apply(np.array).values)\n",
    "y_test = test_df[['zEXT', 'zNEU', 'zAGR', 'zCON', 'zOPN']].values\n",
    "\n",
    "# Create a new linear regression model\n",
    "# model_split = LinearRegression()\n",
    "model_split = Ridge()\n",
    "\n",
    "# Fit the model on the training data\n",
    "model_split.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions_split = model_split.predict(X_test)\n",
    "\n",
    "# Calculate and print the R^2 score for each trait on the test data\n",
    "print(\"R^2 Scores on Test Data (80-20 split):\")\n",
    "for i, trait in enumerate(['zEXT', 'zNEU', 'zAGR', 'zCON', 'zOPN']):\n",
    "    print(f'{trait}: {r2_score(y_test[:, i], predictions_split[:, i])}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
